{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQ6TrdF06uEWIbUig7kCYy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tripatheea/auto/blob/main/just_posterior.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Niel0t6Ye_a0",
        "outputId": "05141184-2a0d-4c74-955f-58e59d408990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.8/dist-packages (0.17.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (1.21.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (1.15.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (4.4.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (0.1.8)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (1.3.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (0.4.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability) (2.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imageio) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from imageio) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-sqgr8bea\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-sqgr8bea\n",
            "  Resolved https://github.com/tensorflow/docs to commit 8f431e2b96ebbebd325a7162a00c40653af799e5\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.8/dist-packages (from tensorflow-docs==0.0.0.dev0) (0.8.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow-docs==0.0.0.dev0) (1.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-docs==0.0.0.dev0) (2.11.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from tensorflow-docs==0.0.0.dev0) (5.7.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-docs==0.0.0.dev0) (3.19.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from tensorflow-docs==0.0.0.dev0) (6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->tensorflow-docs==0.0.0.dev0) (2.0.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (5.1.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (2.16.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (4.3.3)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.8/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (5.7.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (5.10.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (0.19.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->nbformat->tensorflow-docs==0.0.0.dev0) (2.6.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (3.11.0)\n",
            "Building wheels for collected packages: tensorflow-docs\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.0.dev0-py3-none-any.whl size=184468 sha256=3d8c6abc8bc701d01c0b506d2f599b7974871f77ef7c908dd1653ccfb1b40c3e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4gkk74px/wheels/3b/ee/a2/ab4d36a9a4af495bcb936f3e849d4b497b65fa40548a68d6c3\n",
            "Successfully built tensorflow-docs\n",
            "Installing collected packages: tensorflow-docs\n",
            "Successfully installed tensorflow-docs-0.0.0.dev0\n"
          ]
        }
      ],
      "source": [
        "! pip install tensorflow-probability\n",
        "\n",
        "# to generate gifs\n",
        "! pip install imageio\n",
        "! pip install git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import time\n",
        "\n",
        "from tensorflow.python.framework.ops import disable_eager_execution, enable_eager_execution"
      ],
      "metadata": {
        "id": "j1LCh9FufCHN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import keras\n",
        "# from keras import Model\n",
        "# from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Reshape, Dense, Lambda, Flatten\n",
        "# from keras import backend as K\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import glob\n",
        "import skimage\n",
        "import skimage.transform\n",
        "import skimage.io\n",
        "import PIL\n",
        "import numpy as np\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "import imageio\n",
        "# import utils"
      ],
      "metadata": {
        "id": "tVaauFC-fDYD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install corner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFlwAnf6I2hf",
        "outputId": "82b8b1fd-d5b0-48ad-bd2f-994bc1bc3d8e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting corner\n",
            "  Downloading corner-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: matplotlib>=2.1 in /usr/local/lib/python3.8/dist-packages (from corner) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1->corner) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1->corner) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1->corner) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1->corner) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1->corner) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1->corner) (1.15.0)\n",
            "Installing collected packages: corner\n",
            "Successfully installed corner-2.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import corner"
      ],
      "metadata": {
        "id": "humASsJJI373"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enable_eager_execution()"
      ],
      "metadata": {
        "id": "F8zKLspGfETx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WIDTH = 90\n",
        "HEIGHT = 48"
      ],
      "metadata": {
        "id": "xCAiw4XLfFMD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.initializers\n",
        "\n",
        "bandwidth = 0.1\n",
        "\n",
        "f_sig = 20.0\n",
        "\n",
        "fmax = f_sig + 0.5 * bandwidth\n",
        "fmin = f_sig - 0.5 * bandwidth\n",
        "\n",
        "\n",
        "def\tMakeSpectrogram(f_sig = 100., bandwidth = 0.25, Tobs_hr = 24., Tcoh_hr = .25, \n",
        "\t\thnoise = 100., hamp = .4, fsamp = 512., fdot_sig = -1e-6, fdotdot_sig = -1e-10, Omega=0.25, a_p=25,\n",
        "\t\tplot_num = 0, plot = False, write_to_file = False):\n",
        "\t\n",
        "\t##### Defining Variables #####\n",
        "\t# f_sig     --- signal central frequency, hz\n",
        "\t# bandwidth --- bandwidth of search, width of each freq, hz\n",
        "\t# Tobs_hr   --- Length of observation, hrs\n",
        "\t# Tcoh_hr   --- Coherence time, hrs\n",
        "\t# hnoise    --- noise amplitude\n",
        "\t# hamp      --- signal amplitude\n",
        "\t# fsamp     --- sampling frequency, hz\n",
        "\t# fdot_sig  --- Signal frequency derivative \n",
        "\t# plot_num  --- if multiple files is an index\n",
        "\t# whereto   --- Where to save plot\n",
        "\t\n",
        "\t##### Booleans ####\n",
        "\t# plot      \t--- whether or not to plot\n",
        "\t# write_to_file --- whether to save data to .txt file\n",
        "\n",
        "\t#### Returns ####\n",
        "\t# frequency \n",
        "\t# time\n",
        "\t# spectrogram\n",
        "\n",
        "\t# Define constants\n",
        "\tSECS_PER_HOUR = 3600\n",
        "\t\n",
        "\t# Find amplitude spectral density for noise\n",
        "\tnoiseamp = hnoise*np.sqrt(4./fsamp) \n",
        "\t\n",
        "\t\n",
        "\t# Convert observation and coherence time to seconds\n",
        "\tTobs = Tobs_hr * SECS_PER_HOUR\n",
        "\tTcoh = Tcoh_hr * SECS_PER_HOUR\n",
        "\n",
        "\t# Find low and high frequency\n",
        "\t# freqlo_approx = f_sig - 0.5 * bandwidth\n",
        "\t# freqlo = np.floor(freqlo_approx * Tcoh) / Tcoh\n",
        "\t# freqhi = freqlo + bandwidth\n",
        "\n",
        "\tfreqlo, freqhi = fmin, fmax\n",
        "\n",
        "\t# Define time series to hold raw data stream of signal + noise\n",
        "\tdeltat = 1. / fsamp\n",
        "\tt = np.arange(0,Tobs,deltat)\n",
        "\tNsample = len(t)\n",
        "\t# print ('Nsample = %i'%len(t))\n",
        "\t\n",
        "\t# Generate signal in the time domain\n",
        "\tnoise = noiseamp * np.random.normal(0, scale = 1, size = (Nsample,))\n",
        " \n",
        "\tt_asc = 0\n",
        "\t\n",
        "\tfmod = f_sig * (1.0 - a_p * Omega * np.cos(Omega * (t - t_asc)))\t# Should include Doppler term v \\dot n too.\n",
        "\n",
        "\tphi_of_t = 2 * np.pi * (fmod * t + .5 * fdot_sig * t**2 + (1/6) * fdotdot_sig * t**3 )\n",
        " \n",
        "\t# signal = hamp * np.sin(2 * np.pi * (f_sig * t + .5 * fdot_sig * t**2 + (1/6) * fdotdot_sig * t**3 ))\n",
        "\tsignal = hamp * np.sin(phi_of_t)\n",
        " \n",
        "\tdata = signal + noise\n",
        "\n",
        "\t# Generate spectra for each coherence time & extract band of interest to make spectrogram\n",
        "\tindbandlo = int(np.floor(freqlo * Tcoh))\n",
        "\tindbandhi = int(np.floor(freqhi * Tcoh))\n",
        "\tnbandbin  = indbandhi - indbandlo\n",
        "\tNseg = int(np.floor(Tobs / Tcoh))\n",
        "\tNsample_coh = int(np.floor(Nsample / Nseg))\n",
        "\tspectrogram = np.zeros((nbandbin,Nseg),)\t\n",
        "\t# print( np.shape(spectrogram) )\n",
        "\t\n",
        "\tfor seg in range(Nseg):\n",
        "\t\t# print('Generating segment %d\\n'%(seg))\n",
        "\t\tindlo = seg * Nsample_coh\n",
        "\t\tindhi = indlo + Nsample_coh \n",
        "\t\tsegment = data[indlo:indhi]\n",
        "\t\t\n",
        "\t\trawfft = np.fft.fft(segment,Nsample_coh, axis = 0)\n",
        "\t\tspectrogram[:,seg] = 2 * abs(rawfft[indbandlo:indbandhi])\n",
        "\t\t\n",
        "\tsegarray = np.arange(0,Nseg)\n",
        "\tseghour = (segarray) * Tcoh / SECS_PER_HOUR\n",
        "\tindarray = np.arange(indbandlo,indbandhi + 1)\n",
        "\tfreqplot = (indarray - indbandlo)*1.0/Tcoh + freqlo\t\n",
        "  \n",
        "\tif plot:\n",
        "\t\tplt.clf()\n",
        "\t\t# print('Plotting spectrogram')\n",
        "\t\t\n",
        "\t\tplt.pcolormesh(seghour, freqplot, spectrogram)\n",
        "\t\tplt.ylabel('Frequency [Hz]')\n",
        "\t\tplt.xlabel('Time [Hours]')\n",
        "  \n",
        "  \n",
        "\treturn(seghour, freqplot, spectrogram)\n",
        "\n"
      ],
      "metadata": {
        "id": "uQxcvbBNfF76"
      },
      "execution_count": 992,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_dims_and_normalize(s):\n",
        "  \n",
        "  s = np.pad(s, ((0, WIDTH - s.shape[0]), (0, HEIGHT - s.shape[1])))\n",
        "\n",
        "  return (s - np.min(s)) / (np.max(s) - np.min(s))\n",
        "  # return s"
      ],
      "metadata": {
        "id": "6AiICvfjfGgR"
      },
      "execution_count": 993,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bandwidth = 0.1\n",
        "f_sig = 20\n",
        "\n",
        "T_coh = 0.25\n",
        "Tobs_hr = 24\n",
        "\n",
        "fdot_sig = np.random.choice([-1, 1]) * 10**np.random.uniform(-8, -6)\n",
        "\n",
        "\n",
        "fdotdot_sig = np.random.choice([-1, 1]) * 10**np.random.uniform(-13, -12)\n",
        "\n",
        "# fdot_sig = 1e-6\n",
        "\n",
        "fdot_sig, fdotdot_sig"
      ],
      "metadata": {
        "id": "fWru13CRfHM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "283d8eb5-8e8c-4175-e107-7016f068bb1f"
      },
      "execution_count": 994,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.0877204322569355e-08, 1.4441482598579244e-13)"
            ]
          },
          "metadata": {},
          "execution_count": 994
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t, f, spec = MakeSpectrogram(f_sig = np.random.uniform(f_sig - 0.5 * bandwidth, f_sig + 0.5 * bandwidth), bandwidth = bandwidth, Tobs_hr = Tobs_hr, Tcoh_hr = T_coh, \n",
        "              hnoise = np.random.uniform(0.0, 0.001), hamp = np.random.uniform(0.1, 0.5), fsamp = 128., fdot_sig = fdot_sig, \n",
        "              fdotdot_sig=fdotdot_sig, Omega=1e-4, a_p=2, plot_num = 0, plot = True, write_to_file = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "F4Jf6CI8fJu6",
        "outputId": "ffc702d8-6883-4437-e1e5-d1e4bcc7d8bf"
      },
      "execution_count": 1070,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.0 / (bandwidth / 90)"
      ],
      "metadata": {
        "id": "I7wNaZg_sXbs"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spec.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJCAHovxQknn",
        "outputId": "d9fb6e96-90a2-473c-8999-45c464b0bd43"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 96)"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(spec[:,-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "as29NMTHi2aQ",
        "outputId": "da874b93-98d1-44d4-def9-c44f2321af2d"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb3a7ec86d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 204
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.uniform(-8, -6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rpqHWlavbXc",
        "outputId": "3b63cce1-3ab8-4bba-df7f-3f66cb0ada21"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-6.537315994906183"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Max frequency offset in a 24 hour period.\n",
        "\n",
        "delta_t = T_coh * 3600\n",
        "\n",
        "freq_resolution = 1.0 / delta_t\n",
        "\n",
        "fdot_min, fdot_max = 1e-8, 1e-6\n",
        "fdotdot_min, fdotdot_max = 1e-12, 1e-13\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(delta_t, freq_resolution, fdot_min * (Tobs_hr * 60 * 60) * delta_t, fdot_max * (Tobs_hr * 60 * 60) * delta_t)\n",
        "print(fdotdot_min * ((Tobs_hr * 60 * 60)**2) * delta_t, fdotdot_max * ((Tobs_hr * 60 * 60)**2) * delta_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nVQBuDukukf",
        "outputId": "c5e98b44-4057-4d47-e0bf-51fb904b3a07"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "900.0 0.0011111111111111111 0.7776 77.75999999999999\n",
            "6.718464 0.6718464000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_specs = []\n",
        "N = 500\n",
        "\n",
        "\n",
        "\n",
        "f_lower = fmin + 0.25 * (fmax - fmin)\n",
        "f_upper = fmin + 0.75 * (fmax - fmin)\n",
        "\n",
        "f1min, f1max = -8, -6\n",
        "\n",
        "f2min, f2max = -13, -12\n",
        "\n",
        "omega_min, omega_max = -10, -5\n",
        "ap_min, ap_max = 0.0, 2.0\n",
        "\n",
        "def invert_scaling(x, max_val, min_val):\n",
        "  return x * (max_val - min_val) + min_val\n",
        "\n",
        "\n",
        "x_s = []\n",
        "for i in range(N):\n",
        "  # t, f, spec = MakeSpectrogram(f_sig = np.random.random() * 100., bandwidth = 0.05, Tobs_hr = 12., Tcoh_hr = .25, \n",
        "  #             hnoise = 100. + (1 - 2 * np.random.random() * 10.), hamp = .4, fsamp = 128., fdot_sig = -1e-6, \n",
        "  #             plot_num = 0, plot = True, write_to_file = False)\n",
        "  \n",
        "\n",
        "  \n",
        "  freq = np.random.uniform(f_lower, f_upper)\n",
        "  scaled_freq = (freq - fmin) / (fmax - fmin)\n",
        "\n",
        "  \n",
        "  \n",
        "  spindown_exponent = np.random.uniform(f1min, f1max)\n",
        "  spindown = 10**spindown_exponent\n",
        "  scaled_spindown = (spindown_exponent - f1min) / (f1max - f1min)\n",
        "  \n",
        "  fdotdot_sign = np.random.choice([-1, 1])\n",
        "  fdotdot_exponent = np.random.uniform(f2min, f2max)\n",
        "  fdotdot = fdotdot_sign * 10**fdotdot_exponent\n",
        "  scaled_fdotdot = fdotdot_sign * (fdotdot_exponent - f2min) / (f2max - f2min)\n",
        "\n",
        "  omega_exponent = np.random.uniform(omega_min, omega_max)\n",
        "  omega = 10**omega_exponent\n",
        "  scaled_omega = (omega_exponent - omega_min) / (omega_max - omega_min)\n",
        "\n",
        "  a_p = np.random.uniform(ap_min, ap_max)\n",
        "  scaled_a_p = (a_p - ap_min) / (ap_max - ap_min)\n",
        "\n",
        "  # print(freq, spindown, fdotdot)\n",
        "\n",
        "  t, f, spec = MakeSpectrogram(f_sig = freq, bandwidth = bandwidth, Tobs_hr = 12., Tcoh_hr = .25, \n",
        "            hnoise = np.random.uniform(0.0, 0.001), hamp = np.random.uniform(0.1, 0.5), fsamp = 128., fdot_sig = spindown, fdotdot_sig = fdotdot,\n",
        "            Omega=omega, a_p=a_p,\n",
        "            plot_num = 0, plot = False, write_to_file = False)\n",
        "  \n",
        "\n",
        "  freq_start_bin = np.argmax(spec[:,0]) / spec.shape[0]\n",
        "\n",
        "  # scaler = StandardScaler()\n",
        "  # spec = scaler.fit_transform(spec)\n",
        "\n",
        "  r = fix_dims_and_normalize(np.copy(spec))\n",
        "\n",
        "  # print(r.shape)\n",
        "  all_specs.append(r)\n",
        "  x_s.append((scaled_freq, scaled_spindown, scaled_fdotdot, scaled_omega, scaled_a_p, freq_start_bin))\n",
        "\n",
        "  if (i % 100) == 0:\n",
        "    print(f\"i = {i}\")\n",
        "\n",
        "all_specs = np.asanyarray(all_specs)\n",
        "\n",
        "size = len(all_specs)\n",
        "\n",
        "print(all_specs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB-D6wcFfKYT",
        "outputId": "ca0d78b3-33af-463c-eaff-ba7f6eafb098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0\n",
            "i = 100\n",
            "i = 200\n",
            "i = 300\n",
            "i = 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r, spec.shape"
      ],
      "metadata": {
        "id": "l3whEmiRUEHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pcolormesh(all_specs[1,:,:])"
      ],
      "metadata": {
        "id": "Hn7qBFgvUt6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_s"
      ],
      "metadata": {
        "id": "lQ9ON-EiWyeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all_specs"
      ],
      "metadata": {
        "id": "O2Qv7CWXUzuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_s = np.asanyarray(x_s)\n",
        "\n",
        "x_s.shape"
      ],
      "metadata": {
        "id": "YB2UNWVZfLAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "J9mz5l0CENEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x_scaler = StandardScaler()\n",
        "# scaled_x_s = x_scaler.fit_transform(x_s)"
      ],
      "metadata": {
        "id": "QGO1G71lEN66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_x_s = x_s"
      ],
      "metadata": {
        "id": "ZIY2BcJENA5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "1awoW1c4fL8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train_s, x_test_s, y_train_s, y_test_s = train_test_split(x_s, all_specs, test_size=0.2, random_state=42)\n",
        "\n",
        "x_train_s, x_test_s, y_train_s, y_test_s = train_test_split(scaled_x_s, all_specs, test_size=0.2, random_state=42)\n",
        "x_test_s, x_val_s, y_test_s, y_val_s = train_test_split(x_test_s, y_test_s, test_size=0.5, random_state=26)\n",
        "\n",
        "x_train_s.shape"
      ],
      "metadata": {
        "id": "xRHDJExafMnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_s = np.expand_dims(x_train_s, -1)\n",
        "x_test_s = np.expand_dims(x_test_s, -1)\n",
        "x_val_s = np.expand_dims(x_val_s, -1)\n",
        "\n",
        "y_train_s = np.expand_dims(y_train_s, -1)\n",
        "y_test_s = np.expand_dims(y_test_s, -1)\n",
        "y_val_s = np.expand_dims(y_val_s, -1)\n",
        "\n",
        "x_train_s.shape"
      ],
      "metadata": {
        "id": "khtgnkPSfNKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_tensor_utility(x):\n",
        "    return tf.convert_to_tensor(x, dtype=tf.float32)\n",
        "\n",
        " \n",
        "x_train_s, y_train_s, x_test_s, y_test_s, x_val_s, y_val_s = tuple(map(convert_to_tensor_utility, [x_train_s, y_train_s, x_test_s, y_test_s, x_val_s, y_val_s]))"
      ],
      "metadata": {
        "id": "A_SYaXR0fNw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_s.shape, y_train_s.shape"
      ],
      "metadata": {
        "id": "83U5j4OvfOhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_s.shape, y_test_s.shape, y_val_s.shape"
      ],
      "metadata": {
        "id": "6ISRpQCGfPUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train_s"
      ],
      "metadata": {
        "id": "Iz2Xmky8GKQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8"
      ],
      "metadata": {
        "id": "Rrg7Fa14fn9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_s, y_train_s)).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test_s, y_test_s)).batch(batch_size)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val_s, y_val_s)).batch(batch_size)"
      ],
      "metadata": {
        "id": "dGo6GUkJfoqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = dict()\n",
        "\n",
        "params['z_dim'] = 24\n",
        "params['n_modes'] = 1\n",
        "params['n_channels'] = 1\n",
        "params['ramp_start'] = 10\n",
        "params['ramp_end'] = 20\n",
        "params['y_normscale'] = 1.0\n",
        "\n",
        "params['rand_pars'] = ['frequency', 'fdot', 'fdotdot', 'Omega', 'a_p', 'bin']\n",
        "params['inf_pars'] = ['frequency', 'fdot', 'fdotdot', 'Omega', 'a_p', 'bin']\n"
      ],
      "metadata": {
        "id": "p1znqNWCfpPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ramp_func(epoch,start,ramp_length, n_cycles):\n",
        "    i = (epoch - start) / (2.0 * ramp_length)\n",
        "    # print(epoch,i)\n",
        "    \n",
        "    if i < 0:\n",
        "        return 0.0\n",
        "    if i >= n_cycles:\n",
        "        return 1.0\n",
        "    \n",
        "    return min(1.0, 2.0 * np.remainder(i, 1.0))\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "initializer = tf.keras.initializers.GlorotUniform()"
      ],
      "metadata": {
        "id": "sLt_iTgrfqqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_encoder_block(x, num_filters, act):  \n",
        "    \"\"\"\n",
        "    Todo: Define two sequential 2D convolutional layers (Conv2D) with the following properties:\n",
        "          - num_filters many filters\n",
        "          - kernel_size 3\n",
        "          - activation \"relu\"\n",
        "          - padding \"same\"\n",
        "          - kernel_initializer \"he_normal\"\n",
        "          Also define a 2D max pooling layer (MaxPooling2D) (you can keep default arguments).\n",
        "    \"\"\"\n",
        "    x = tf.keras.layers.Conv2D(num_filters, 4, activation=act, padding='same', kernel_initializer='he_normal')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Conv2D(num_filters, 4, activation=act, padding='same', kernel_initializer='he_normal')(x)\n",
        "    x = tf.keras.layers.MaxPooling2D()(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    \n",
        "    return x"
      ],
      "metadata": {
        "id": "u1gB6LC_geQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_decoder_block(x, num_filters, act):\n",
        "    \"\"\"\n",
        "    Todo: Define one 2D upsampling layer (UpSampling2D) (you can keep default arguments).\n",
        "          Also, define two sequential 2D convolutional layers (Conv2D) with the following properties:\n",
        "          - num_filters many filters\n",
        "          - kernel_size 3\n",
        "          - activation \"relu\"\n",
        "          - padding \"same\"\n",
        "          - kernel_initializer \"he_normal\"\n",
        "    \"\"\"\n",
        "    x = tf.keras.layers.UpSampling2D()(x)\n",
        "    x = tf.keras.layers.Conv2DTranspose(num_filters, 4, activation=act, padding = 'same', kernel_initializer = 'he_normal')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Conv2DTranspose(num_filters, 4, activation=act, padding = 'same', kernel_initializer = 'he_normal')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "G1sXEcj5OZjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CVAE(tf.keras.Model):\n",
        "    \"\"\"Convolutional variational autoencoder.\"\"\"\n",
        "\n",
        "    def __init__(self, x_dim, y_dim, n_channels, z_dim, n_modes, params):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.n_modes = n_modes\n",
        "        self.x_modes = 1   # hardcoded for testing\n",
        "        self.x_dim = x_dim\n",
        "        self.y_dim = y_dim\n",
        "        self.n_channels = n_channels\n",
        "        self.act = tf.keras.layers.LeakyReLU(alpha=0.3)\n",
        "        self.params = params\n",
        "        self.reg = regularizers.l2(0.1)\n",
        "\n",
        "\n",
        "        start_filters = 16\n",
        "\n",
        "        \"\"\"\n",
        "        # Add this to get rid of regularizer\n",
        "        a2 = tf.keras.layers.Dense(2*self.z_dim*self.n_modes + self.n_modes)(a2)\n",
        "        self.encoder_r1 = tf.keras.Model(inputs=r1_input_y, outputs=a2)\n",
        "        print(self.encoder_r1.summary())\n",
        "        \"\"\"\n",
        "        \n",
        "        # the r1 encoder network- r1_encoder(y) = z'.\n",
        "\n",
        "        r1_input_y = tf.keras.Input(shape=(WIDTH, HEIGHT, 1))\n",
        "\n",
        "        eblock1 = define_encoder_block(r1_input_y, start_filters, self.act)\n",
        "        eblock2 = define_encoder_block(eblock1, start_filters*2, self.act)\n",
        "        eblock3 = define_encoder_block(eblock2, start_filters*4, self.act)\n",
        "        eblock4 = define_encoder_block(eblock3, start_filters*8, self.act)\n",
        "        # eblock4 = eblock2\n",
        "        _, *shape_spatial = eblock4.get_shape().as_list()\n",
        "        eblock4_flat = tf.keras.layers.Flatten()(eblock4)\n",
        "\n",
        "        x = tf.keras.layers.BatchNormalization(name='bn_2')(eblock4_flat)\n",
        "        a2 = tf.keras.layers.Dense(16, kernel_regularizer=self.reg, activation=self.act)(x)\n",
        "        a2 = tf.keras.layers.Dropout(.1)(a2)\n",
        "        a2 = tf.keras.layers.Dense(8, kernel_regularizer=self.reg, activation=self.act)(a2)\n",
        "        a2 = tf.keras.layers.Dropout(.1)(a2)\n",
        "        # a2 = x\n",
        "        a2 = tf.keras.layers.Dense(16, kernel_regularizer=self.reg, activation=self.act)(a2)\n",
        "        a2 = tf.keras.layers.BatchNormalization()(a2)\n",
        "        a2 = tf.keras.layers.Dense(2*self.z_dim*self.n_modes + self.n_modes, activation=self.act, kernel_regularizer=self.reg)(a2)\n",
        "        self.encoder_r1 = tf.keras.Model(inputs=r1_input_y, outputs=a2)\n",
        "\n",
        "        print(self.encoder_r1.summary())\n",
        "\n",
        "\n",
        "        # the q encoder network- q_encoder(x, y) = z''.\n",
        "\n",
        "        q_input_x = tf.keras.Input(shape=(self.x_dim))\n",
        "        c = tf.keras.layers.Flatten()(q_input_x)\n",
        "        d = tf.keras.layers.concatenate([eblock4_flat, c])\n",
        "        d = tf.keras.layers.BatchNormalization()(d)\n",
        "        e = tf.keras.layers.Dense(16, kernel_regularizer=self.reg, activation=self.act)(d)\n",
        "        e = tf.keras.layers.Dropout(.1)(e)\n",
        "        # e = d\n",
        "        e = tf.keras.layers.Dense(16, kernel_regularizer=self.reg, activation=self.act)(e)\n",
        "        e = tf.keras.layers.BatchNormalization()(e)\n",
        "        e = tf.keras.layers.Dense(2*self.z_dim, activation=self.act)(e)\n",
        "        self.encoder_q = tf.keras.Model(inputs=[r1_input_y, q_input_x], outputs=e)\n",
        "\n",
        "\n",
        "        print(self.encoder_q.summary())\n",
        "\n",
        "\n",
        "        # the r2 decoder network- r2_decoder(y, z) = x'.\n",
        "\n",
        "        r2_input_z = tf.keras.Input(shape=(self.z_dim))\n",
        "        g = tf.keras.layers.Flatten()(r2_input_z)\n",
        "\n",
        "        '''\n",
        "        # x = tf.keras.layers.Dense(8, kernel_regularizer=self.reg, activation=self.act)(r2_input_z)\n",
        "\n",
        "        # x = tf.reshape(x, [-1, 8, 8, 64])\n",
        "\n",
        "        x = tf.keras.layers.Dense(np.prod(shape_spatial), kernel_regularizer=self.reg, activation=self.act)(r2_input_z)  # \n",
        "        x = tf.keras.layers.Reshape(eblock4.shape.as_list()[1:])(x)                     # (None, 1, , 64)\n",
        "\n",
        "        dblock1 = define_decoder_block(x, start_filters)\n",
        "        dblock2 = define_decoder_block(dblock1, start_filters * 2)\n",
        "        dblock3 = define_decoder_block(dblock2, start_filters * 4)\n",
        "        dblock4 = define_decoder_block(dblock3, start_filters * 8)\n",
        "        # dblock4 = dblock2\n",
        "\n",
        "        g = tf.keras.layers.Flatten()(dblock4)\n",
        "        h = tf.keras.layers.concatenate([eblock4_flat, g])\n",
        "        \n",
        "        h = tf.keras.layers.BatchNormalization()(h)\n",
        "        i = tf.keras.layers.Dense(8, kernel_regularizer=self.reg, activation=self.act)(h)\n",
        "        # i = tf.keras.layers.Dropout(.1)(i)\n",
        "        # i = tf.keras.layers.Dense(8, kernel_regularizer=self.reg, activation=self.act)(i)\n",
        "        # i = tf.keras.layers.BatchNormalization()(i)\n",
        "        # i = tf.keras.layers.Dense(4, kernel_regularizer=self.reg, activation=self.act)(i)\n",
        "        # i = tf.keras.layers.BatchNormalization()(i)\n",
        "        j = tf.keras.layers.Dense(2*self.x_dim*self.x_modes + self.x_modes)(i)\n",
        "\n",
        "        print(\"Decoder summary:\")\n",
        "\n",
        "        self.decoder_r2 = tf.keras.Model(inputs=[r1_input_y, r2_input_z], outputs=j)\n",
        "        '''\n",
        "\n",
        "        h = tf.keras.layers.concatenate([eblock4_flat, g])\n",
        "        h = tf.keras.layers.BatchNormalization(name='bn_6')(h)\n",
        "        i = tf.keras.layers.Dense(32, kernel_regularizer=self.reg, activation=self.act)(h)\n",
        "        i = tf.keras.layers.Dropout(.5)(i)\n",
        "        i = tf.keras.layers.Dense(16, kernel_regularizer=self.reg, activation=self.act)(i)\n",
        "        i = tf.keras.layers.BatchNormalization(name='bn_7')(i)\n",
        "        j = tf.keras.layers.Dense(2*self.x_dim*self.x_modes + self.x_modes, activation=self.act)(i)\n",
        "        self.decoder_r2 = tf.keras.Model(inputs=[r1_input_y, r2_input_z], outputs=j)\n",
        "\n",
        "        print(self.decoder_r2.summary())\n",
        "        # During use, we would only have y. Use r1_encoder(y) = z'. Then, use r2_decoder(y, z') = x' to get the prediction / posterior.\n",
        "    \n",
        "    def get_encoders(self):\n",
        "        return self.encoder_r1, self.encoder_q\n",
        "    \n",
        "    def encode_r1(self, y=None):\n",
        "#         print(\"==\")\n",
        "#         print(y)\n",
        "#         print(\"AAA\")\n",
        "#         print(self.encoder_r1(y).shape)\n",
        "#         print(self.encoder_r1(y))\n",
        "# #         print([self.z_dim*self.n_modes, self.z_dim*self.n_modes,self.n_modes])\n",
        "#         print(\"==\")\n",
        "#         print(self.z_dim*self.n_modes + self.z_dim*self.n_modes + self.n_modes)\n",
        "        \n",
        "#         mean, logvar, weight = tf.split(self.encoder_r1(y), num_or_size_splits=[2, 4, 3], axis=1)\n",
        "\n",
        "        encoded_y = self.encoder_r1(y)  # (4, 17)\n",
        "\n",
        "        # print(encoded_y.shape)\n",
        "        mean, logvar, weight = tf.split(encoded_y, num_or_size_splits=[self.z_dim*self.n_modes, self.z_dim*self.n_modes,self.n_modes], axis=1)\n",
        "        \n",
        "        # print(mean.shape, logvar.shape, weight.shape) # (4, 8), (4, 8), (4, 1)\n",
        "        \n",
        "        # Becomes (4, 1, 2) (4, 2, 1)\n",
        "        return tf.reshape(mean,[-1,self.n_modes,self.z_dim]), tf.reshape(logvar,[-1,self.n_modes,self.z_dim]), tf.reshape(weight,[-1,self.n_modes])\n",
        "\n",
        "\n",
        "    def encode_q(self, x=None, y=None):\n",
        "        return tf.split(self.encoder_q([y,x]), num_or_size_splits=[self.z_dim, self.z_dim], axis=1)\n",
        "\n",
        "    def decode_r2(self, y=None, z=None, apply_sigmoid=False):\n",
        "        \n",
        "#         print(\"AA\", self.decoder_r2([y, z]).shape)\n",
        "#         print(\"BB\", [2 * self.x_dim * self.x_modes, self.x_modes])\n",
        "        mean, logvar, weight = tf.split(self.decoder_r2([y, z]), num_or_size_splits=[self.x_dim*self.x_modes, self.x_dim*self.x_modes, self.x_modes], axis=1)\n",
        "        return tf.reshape(mean,[-1,self.x_modes,self.x_dim]), tf.reshape(logvar,[-1,self.x_modes,self.x_dim]), tf.reshape(weight,[-1,self.x_modes])"
      ],
      "metadata": {
        "id": "tVciQBfofru-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPS = 1e-6\n",
        "dist_mask = np.array([True])\n",
        "not_dist_mask = np.array([True])\n",
        "\n",
        "bounds = dict(a=0.0, b=30.0)\n",
        "\n",
        "\n",
        "# KL[P || Q] = S(P) - H(P, Q)               Model P with approximation Q.\n",
        "# KL[Q || P] = S(Q) - H(Q, P)               Model Q with approximation P.\n",
        "\n",
        "# Variational Autoencoders:\n",
        "#  Let X be the data we want to model, z is the latent variable. Pr[X] = distn of data. Pr[z] latent distrn. Pr[X | z] = distrn of generating data | latent variable.\n",
        "#  We want to infer Pr[z] from Pr[z | X] which is the distrn that projects our data into the latent space.  \n",
        "#  But we do not know Pr[z | X], so we use a simpler estimate of Qr[z | X].\n",
        "\n",
        "# KL( Qr[z | X] || Pr[z | X] ) = E{ log( Qr[z | X] ) - log( Pr[z | X] ) } summed up over Qr[z | X]. \n",
        "# KL = H(Q, P) - S(Q) = cross-entropy between Q and P - entropy of P => info in just P - info overlap between P and Q => remaining info in P that we missed. \n",
        "\n",
        "\n",
        "# Ingredients:\n",
        "#   - Qr[z | x]\n",
        "#   - \n",
        "\n",
        "# Infer z_mean, z_var from just y.               Use encoder r1._samp            A = Pr[z | y].\n",
        "# \n",
        "# Infer z'_mean', z'_var' from x, y to get z_sample.                        B = Pr[z | x, y] => sample z_samp from q. We later calculate self-entropy of this.\n",
        "# Use encoder q for this.  Qr[z_sample | x, y]. Calculate self-entropy.\n",
        "# C = Pr[z_samp | y] = x_samp.\n",
        "# \n",
        "# Pr[z | x, y] is the \"real\" / actual distribution. So we want self-entropy of that - cross-entropy of that with Pr[z_samp | y].\n",
        "# What we are doing is that we are looking at how much information we are missing by calculating z_samp using Pr[z | y] instead of the actual distribution\n",
        "# of Pr[z | x, y]. This gives us our KL divergence, which we want to minimize.\n",
        "\n",
        "\n",
        "# Decode (z_sample, y) to get a distribution for x. Pr[x | z_samp, y]. Then, calculate the probability of getting x_actual under this distribution (log-likelihood).\n",
        "# The higher the probability the better it is, which we want to maximize.\n",
        "\n",
        "# Total Loss = (2) - (1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# XXXXX\n",
        "# Calculate self-entropy with Pr[z_samp] from inference of z_mean with y i.e. Pr[z_mean | y].  So entropy of Pr[z | x, y]. \n",
        "# This is the real distribution P. We are approximating it with Qr[z | y]. So we want S[ Pr[z | x, y] ] - H[Pr[z|x,y], Pr[z|y]].\n",
        "# Pr[z_samp] under A / r1.\n",
        "\n",
        "# \n",
        "\n",
        "tfd = tfp.distributions\n",
        "\n",
        "def compute_loss(model, x, y, ramp=1.0, noiseamp=1.0):\n",
        "    \n",
        "#     print(\"Computing loss.\")\n",
        "    \n",
        "    old_old_x = x\n",
        "    \n",
        "    noiseamp = tf.cast(noiseamp, dtype=tf.float32)\n",
        "    y_normscale = tf.cast(params['y_normscale'], dtype=tf.float32)\n",
        "    y = tf.cast(y, dtype=tf.float32)\n",
        "    x = tf.cast(x, dtype=tf.float32)\n",
        "    \n",
        "    y = (y + noiseamp*tf.random.normal(shape=tf.shape(y), mean=0.0, stddev=1.0, dtype=tf.float32)) / y_normscale\n",
        "    \n",
        "    # print(\"x\", x)\n",
        "    \n",
        "    # print(\"y\", y)\n",
        "    \n",
        "    # This is in the latent space z. z just from y.\n",
        "    mean_r1, logvar_r1, logweight_r1 = model.encode_r1(y=y)             # Infer z_mean, z_var by encoding y.\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    scale_r1 = EPS + tf.sqrt(tf.exp(logvar_r1))                         # Fix to enable backpropagation.\n",
        "\n",
        "    # Sample from the latent space. z just from y.\n",
        "    gm_r1 = tfd.MixtureSameFamily(mixture_distribution=tfd.Categorical(logits=logweight_r1),\n",
        "            components_distribution=tfd.MultivariateNormalDiag(\n",
        "            loc=mean_r1,\n",
        "            scale_diag=scale_r1))\n",
        "    \n",
        "    # Latent space. z from x and y.\n",
        "    mean_q, logvar_q = model.encode_q(x=x, y=y)                         # Infer z'_mean and z'_var by encoding x and y.\n",
        "    scale_q = EPS + tf.sqrt(tf.exp(logvar_q))                           # Fix to enable backpropagation.\n",
        "    \n",
        "    \n",
        "    \n",
        "    # print(np.mean(mean_r1))\n",
        "    \n",
        "    # Sample from the latent space. z from x and y.\n",
        "    mvn_q = tfp.distributions.MultivariateNormalDiag(\n",
        "                          loc=mean_q,\n",
        "                          scale_diag=scale_q)\n",
        "    \n",
        "    z_samp = mvn_q.sample()                                               # Sample z_samp from a multi-variate normal distribution (inferred from (x, y)).\n",
        "    \n",
        "    # print(z_samp)\n",
        "    # Take the latent sample and y to reconstruct x. Pr[x | y, z]\n",
        "    mean_r2, logvar_r2, logweight_r2 = model.decode_r2(y=y, z=z_samp)     # Decode (z_samp, y) to get predicted x'.\n",
        "    scale_r2 = EPS + tf.sqrt(tf.exp(logvar_r2))\n",
        "    \n",
        "    # This is a sample from x.\n",
        "    # print(\"Drawn f = \", np.mean(mean_r2), end=\", \")\n",
        "    \n",
        "    # Distribution for x. Pr[x | y, z]\n",
        "    mvn_r2 = tfd.MixtureSameFamily(mixture_distribution=tfd.Categorical(logits=logweight_r2),      # Sample predicted x'.\n",
        "            components_distribution=tfd.MultivariateNormalDiag(\n",
        "            loc=mean_r2,\n",
        "            scale_diag=scale_r2))\n",
        "    \n",
        "\n",
        "    # print(mean_r2.shape, old_old_x.shape)\n",
        "    \n",
        "    simple_cost_recon = -1.0*tf.reduce_mean(tf.reduce_sum(mvn_r2.log_prob(x)))                            # Calculate the odds of having the x_actual. Pr[x | y, z_samp].\n",
        "\n",
        "    # print(simple_cost_recon)\n",
        "    \n",
        "    selfent_q = -1.0*tf.reduce_mean(mvn_q.entropy())                                         # Self-entropy of q-encoder [(x, y) => z_samp]. H(z_samp(x, y)).\n",
        "    log_r1_q = gm_r1.log_prob(z_samp)   # evaluate the log prob of r1 at the q samples       # Pr[z_samp | x, y].\n",
        "    cost_KL = selfent_q - tf.reduce_mean(log_r1_q)                                           # KL-div with self-entropy - cross-entropy.\n",
        "    \n",
        "    # KL = H(z_samp(x, y)) - Pr[z_samp | x, y].\n",
        "    \n",
        "    \n",
        "    return simple_cost_recon, cost_KL"
      ],
      "metadata": {
        "id": "IWHHh5M9fsqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_metric = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
        "\n",
        "@tf.function\n",
        "def train_step(model, x, y, optimizer, ramp=1.0):\n",
        "    \"\"\"Executes one training step and returns the loss.\n",
        "    This function computes the loss and gradients, and uses the latter to\n",
        "    update the model's parameters.\n",
        "    \"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "        r_loss, kl_loss = compute_loss(model, x, y, ramp=ramp)\n",
        "        # r_loss, kl_loss = compute_loss(model, x, y)\n",
        "        loss = r_loss + ramp * kl_loss\n",
        "        \n",
        "    gradients = tape.gradient(loss, model.trainable_variables, unconnected_gradients=tf.UnconnectedGradients.ZERO)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    \n",
        "    train_loss_metric(loss)\n",
        "    \n",
        "    return r_loss, kl_loss, loss"
      ],
      "metadata": {
        "id": "6-GzauiEfujy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs = 250\n",
        "ramp_start = 50\n",
        "ramp_length = 100\n",
        "\n",
        "\n",
        "ramp_cycles = 1\n",
        "ramp_list = [ramp_func(ep, ramp_start, ramp_length, ramp_cycles) for ep in np.arange(0, epochs, 1)]\n",
        "\n",
        "plt.plot(ramp_list)"
      ],
      "metadata": {
        "id": "i8R_-JNgyHMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yN8eylH606eK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = (25 - ramp_start) / (2.0 * ramp_length)\n",
        "\n",
        "print(i)\n",
        "# print(epoch,i)\n",
        "\n",
        "print(2.0 * np.remainder(i, 1.0))\n",
        "\n",
        "# if i < 0:\n",
        "#     return 0.0\n",
        "# if i >= n_cycles:\n",
        "#     return 1.0\n",
        "\n",
        "# return min(1.0, 2.0 * np.remainder(i, 1.0))"
      ],
      "metadata": {
        "id": "rSFRkpyzyZvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "\n",
        "# start the training loop\n",
        "train_loss = np.zeros((epochs, 3))\n",
        "test_loss = np.zeros((epochs, 3))\n",
        "\n",
        "KL_samples = []\n",
        "\n",
        "\n",
        "\n",
        "model = CVAE(x_dim=6, y_dim=1, n_channels=params['n_channels'], \\\n",
        "             z_dim=params['z_dim'], n_modes=1, params=params)\n",
        "\n",
        "model.compile()"
      ],
      "metadata": {
        "id": "ano40u3hfweq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_s[1:2,:,0].shape, y_train_s[1:2,:,:,0].shape"
      ],
      "metadata": {
        "id": "RKs_Xhymfxai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.encode_r1(y_train_s[1:2,:,:,0])"
      ],
      "metadata": {
        "id": "mE1dsqWVk3hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.encode_q(x_train_s[1:2,:,0], y_train_s[1:2,:,:,0])"
      ],
      "metadata": {
        "id": "84wsMWc1k8Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.decode_r2(y_train_s[1:2,:,:,0], np.random.normal(0, 1, (1, params['z_dim'])))"
      ],
      "metadata": {
        "id": "r7GlLvcqlPK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_s[1:2,:,0].shape, y_train_s[1:2,:,:,0].shape"
      ],
      "metadata": {
        "id": "eSIIopj_EWi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_loss(model, x_train_s[1:2,:,0], y_train_s[1:2,:,:,0])"
      ],
      "metadata": {
        "id": "V8Uf1mtbldn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ramp_grad = 0.025\n",
        "\n",
        "plt.plot([np.min([(epoch-ramp_start)*ramp_grad,1.0]) if epoch > ramp_start else 0.0 for epoch in range(0, epochs, 1)])"
      ],
      "metadata": {
        "id": "LvHTmwuFmUMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.metrics.Mean()\n",
        "\n",
        "print(\"Running with\", epochs, \"epochs.\")\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    temp_train_r_loss, temp_train_kl_loss, temp_train_loss = 0.0, 0.0, 0.0\n",
        "    temp_test_r_loss, temp_test_kl_loss, temp_test_loss = 0.0, 0.0, 0.0\n",
        "\n",
        "    \n",
        "    \n",
        "    current_ramp = (np.min([(epoch-ramp_start)*ramp_grad,1.0]).astype(np.single) if epoch>ramp_start else 0.0)\n",
        "    \n",
        "    # print(ramp)\n",
        "    \n",
        "    for step, (x_batch_train, y_batch_train) in train_dataset.enumerate():\n",
        "        x_b = x_batch_train[:,:,0]\n",
        "        # print(\"x_batch, y_batch\", x_b.shape, y_batch_train.shape)    \n",
        "        temp_train_r_loss, temp_train_kl_loss, temp_train_loss = train_step(model, x_b, y_batch_train, optimizer, ramp=current_ramp)\n",
        "        train_loss[epoch - 1, 0] += temp_train_r_loss / len(train_dataset)\n",
        "        train_loss[epoch - 1, 1] += temp_train_kl_loss / len(train_dataset)\n",
        "        train_loss[epoch - 1, 2] += temp_train_loss / len(train_dataset)\n",
        "        \n",
        "    for step, (x_batch_test, y_batch_test) in test_dataset.enumerate():\n",
        "        x_b_t = x_batch_test[:,:,0]\n",
        "        temp_test_r_loss, temp_test_kl_loss = compute_loss(model, x_b_t, y_batch_test)\n",
        "        test_loss[epoch - 1, 0] += temp_test_r_loss / len(test_dataset)\n",
        "        test_loss[epoch - 1, 1] += temp_test_kl_loss / len(test_dataset)\n",
        "        # test_loss[epoch - 1, 2] += temp_test_loss / len(test_dataset)\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "        print(\"epoch = %d; train loss = %.4e, train KL = %.4e; train total: %.4e; test loss = %.4e, test KL = %.4e\" % \\\n",
        "              (epoch, train_loss[epoch - 1, 0], train_loss[epoch - 1, 1], train_loss[epoch - 1, 2], \\\n",
        "               test_loss[epoch - 1, 0], test_loss[epoch - 1, 1]))\n"
      ],
      "metadata": {
        "id": "kCq66Kobly49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5), dpi=150)\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.plot(train_loss[:,0], label=\"Train R Loss\")\n",
        "# plt.plot(test_loss[:,0], label=\"Test R Loss\")\n",
        "plt.plot(train_loss[:,1], label=\"Train KL Loss\")\n",
        "plt.plot(train_loss[:,2], label=\"Train Total Loss\")\n",
        "\n",
        "# plt.ylim(0, 0.1)\n",
        "\n",
        "plt.legend()\n",
        "# plt.yscale('log')\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(test_loss[:,0], label=\"Test R Loss\")\n",
        "plt.plot(test_loss[:,1], label=\"Test KL Loss\")\n",
        "\n",
        "# plt.ylim(0, 0.15)\n",
        "\n",
        "plt.legend()\n",
        "# plt.yscale('log')"
      ],
      "metadata": {
        "id": "7CONJyTtmIGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_z_samples(model, x, y, nsamples=1000):\n",
        "    \n",
        "    y = y / params['y_normscale']\n",
        "    y = tf.tile(y,(nsamples, 1, 1))\n",
        "    x = tf.tile(x,(nsamples, 1))\n",
        "    \n",
        "    mean_r1, logvar_r1, logweight_r1 = model.encode_r1(y=y)\n",
        "    \n",
        "    scale_r1 = EPS + tf.sqrt(tf.exp(logvar_r1))\n",
        "    \n",
        "    gm_r1 = tfd.MixtureSameFamily(mixture_distribution=tfd.Categorical(logits=logweight_r1),\n",
        "            components_distribution=tfd.MultivariateNormalDiag(\n",
        "            loc=mean_r1,\n",
        "            scale_diag=scale_r1))\n",
        "    \n",
        "    z_samp_r1 = gm_r1.sample()\n",
        "    \n",
        "    mean_q, logvar_q = model.encode_q(x=x,y=y)\n",
        "    \n",
        "    scale_q = EPS + tf.sqrt(tf.exp(logvar_q))\n",
        "    mvn_q = tfp.distributions.MultivariateNormalDiag(\n",
        "                          loc=mean_q,\n",
        "                          scale_diag=scale_q)\n",
        "    \n",
        "    z_samp_q = mvn_q.sample()    \n",
        "    \n",
        "    return mean_r1, z_samp_r1, mean_q, z_samp_q"
      ],
      "metadata": {
        "id": "9BlnypwCFwEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_samples(model, y, ramp=1.0, nsamples=100, max_samples=10):    # Generate samples from (test) y.\n",
        "\n",
        "    y = y\n",
        "    y = tf.tile(y, (max_samples, 1, 1, 1))\n",
        "    \n",
        "    samp_iterations = int(nsamples / max_samples)\n",
        "\n",
        "    print(\"samp_iterations\", samp_iterations)\n",
        "    \n",
        "    x_sample = []\n",
        "    for i in range(samp_iterations):\n",
        "        mean_r1, logvar_r1, logweight_r1 = model.encode_r1(y=y) # Encode y to get z.\n",
        "        scale_r1 = EPS + tf.sqrt(tf.exp(logvar_r1))\n",
        "        \n",
        "        gm_r1 = tfd.MixtureSameFamily(mixture_distribution=tfd.Categorical(logits=logweight_r1),\n",
        "            components_distribution=tfd.MultivariateNormalDiag(\n",
        "            loc=mean_r1,\n",
        "            scale_diag=scale_r1))\n",
        "        \n",
        "        z_samp = gm_r1.sample()   # Sample a z_samp.\n",
        "        \n",
        "        mean_r2, logvar_r2, logweight_r2 = model.decode_r2(z=z_samp,y=y)  # Decode (z_samp, y) => x\n",
        "        scale_r2 = EPS + tf.sqrt(tf.exp(logvar_r2))\n",
        "        \n",
        "        gm_r2 = tfd.MixtureSameFamily(mixture_distribution=tfd.Categorical(logits=logweight_r2),    \n",
        "            components_distribution=tfd.MultivariateNormalDiag(\n",
        "            loc=mean_r2,\n",
        "            scale_diag=scale_r2))\n",
        "\n",
        "        current_sample = gm_r2.sample()\n",
        "        # current_sample_inverse_transformed = x_scaler.inverse_transform(current_sample)\n",
        "\n",
        "        if i == 0:\n",
        "            x_sample = current_sample   # Sample an x.\n",
        "        else:\n",
        "            x_sample = tf.concat([x_sample, current_sample],axis=0)\n",
        "\n",
        "\n",
        "    return x_sample\n"
      ],
      "metadata": {
        "id": "xu5RKouJF0yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bounds = {'frequency_min': fmin, 'frequency_max': fmax}\n",
        "\n",
        "defaults_kwargs = dict(\n",
        "                    bins=50, smooth=0.9, label_kwargs=dict(fontsize=16),\n",
        "                    title_kwargs=dict(fontsize=16),\n",
        "                    truth_color='#4682b4', quantiles=[0.16, 0.84],\n",
        "                    levels=(0.68,0.90,0.95), density=True,\n",
        "                    plot_density=False, plot_datapoints=True,\n",
        "                    max_n_ticks=3)\n",
        "\n",
        "\n",
        "hist_kwargs = dict(density=True,color='tab:red')\n",
        "hist_kwargs_other = dict(density=True,color='tab:blue')"
      ],
      "metadata": {
        "id": "3TRdoujQF2dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_dir = \"./\"\n",
        "params['n_samples'] = 100\n",
        "\n",
        "run = plot_dir"
      ],
      "metadata": {
        "id": "ZN-P1UPxF6L1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params['corner_labels'] = {'frequency': 'frequency', 'fdot': 'fdot', 'fdotdot': 'fdotdot', 'Omega': 'Omega', 'a_p': 'a_p', 'bin': 'bin'}"
      ],
      "metadata": {
        "id": "_Y1REeOXIyDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# invert_scaling(x, max_value, min_value)\n",
        "\n",
        "min_max_values = [(fmin, fmax), (f1min, f1max), (f2min, f2max), (omega_min, omega_max), (ap_min, ap_max), (0, 90)]\n",
        "\n",
        "min_max_values"
      ],
      "metadata": {
        "id": "PKTKnwmgiAFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_posterior(dataset):\n",
        "\n",
        "  for step, (x_batch, y_batch) in dataset.enumerate():\n",
        "\n",
        "      if step > 1:\n",
        "        break\n",
        "\n",
        "      samples = gen_samples(model, y_batch, ramp=1.0, nsamples=params['n_samples'], max_samples=100)\n",
        "\n",
        "      print('Epoch: {}, run {} Testing time elapsed for {} samples.'.format(epoch,run,params['n_samples']))\n",
        "\n",
        "      # print(np.mean(samples), np.mean(x_truth))\n",
        "      # print(samples)\n",
        "\n",
        "      # x_truth = x_scaler.inverse_transform(x_batch)\n",
        "      # x_truth = np.expand_dims(x_scaler.inverse_transform(x_batch[:,:,0]), -1)\n",
        "\n",
        "      # x_batch[:,:-1]\n",
        "      x_truth = x_batch    # Exclude the very last parameter\n",
        "\n",
        "      # tf.reduce_mean(x_truth[:,:,0], axis=(0))\n",
        "\n",
        "      sample_mean = tf.math.reduce_mean(samples, axis=0)\n",
        "      sample_std = tf.math.reduce_std(samples, axis=0)\n",
        "      x_truth_mean = tf.math.reduce_mean(x_truth[:,:,0], axis=0)\n",
        "      x_truth_std = tf.math.reduce_std(x_truth[:,:,0], axis=0)\n",
        "\n",
        "      # print(type(sample_mean), type(x_truth_mean))\n",
        "      # diff = 100 * np.abs(sample_mean - x_truth_mean) / x_truth_mean\n",
        "      diff = -1\n",
        "\n",
        "      # print(\"Mean of sample = %.2f (%.2f); mean of truth = %.2f (%.2f); difference = %.2f percent.\" % (sample_mean, sample_std, x_truth_mean, x_truth_std, diff))\n",
        "      \n",
        "      # print(\"Mean of sample = \", end=\"\\t\")\n",
        "      # print(sample_mean)\n",
        "      # print(\" x truth mean = \", end=\"\\t\")\n",
        "      # print(x_truth_mean)\n",
        "      # print(\" diff = \", end=\"\\t\")\n",
        "      # print(diff)\n",
        "      \n",
        "\n",
        "      # print(params['corner_labels'])\n",
        "      # Get corner parnames to use in plotting labels\n",
        "      parnames = []\n",
        "      for k_idx, k in enumerate(params['rand_pars']):\n",
        "          # print(k_idx, k)\n",
        "          if np.isin(k, params['inf_pars']):\n",
        "              parnames.append(params['corner_labels'][k])\n",
        "\n",
        "      full_true_x = np.zeros(x_truth.shape[1:])\n",
        "      new_samples = np.zeros([samples.shape[0], len(params['inf_pars'])])\n",
        "\n",
        "      # print(full_true_x.shape)\n",
        "      # print(x_truth[0].shape)\n",
        "      for inf_par_idx, inf_par in enumerate(params['inf_pars']):\n",
        "        min_max_value = min_max_values[inf_par_idx]\n",
        "        # print(inf_par_idx)\n",
        "        new_samples[:,inf_par_idx] = invert_scaling(samples[:,inf_par_idx], min_max_value[0], min_max_value[1])\n",
        "        # print(min_max_value)\n",
        "        # print(new_samples[:,inf_par_idx][0:5])\n",
        "        # break\n",
        "        full_true_x[inf_par_idx] = invert_scaling(x_truth[0, inf_par_idx, 0], min_max_value[0], min_max_value[1])\n",
        "      \n",
        "      print(\"Full true x = \", full_true_x[:,0])\n",
        "      # plt.subplot(width, height, step + 1)\n",
        "      figure = corner.corner(new_samples, **defaults_kwargs,labels=parnames,\n",
        "                        color='tab:red',\n",
        "                        fill_contours=True, truths=full_true_x[:,0],\n",
        "                        show_titles=True, hist_kwargs=hist_kwargs)\n",
        "      \n",
        "      figure.suptitle(\" \".join([f\"{t:.2f}\" for t in full_true_x[:,0]]))\n",
        "\n",
        "      figure.set_tight_layout(True)"
      ],
      "metadata": {
        "id": "87p4II7XF6a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_posterior(train_dataset)"
      ],
      "metadata": {
        "id": "VRlfM4zNGJkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params['inf_pars']"
      ],
      "metadata": {
        "id": "H1uN0uQZjyas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_posterior(test_dataset)"
      ],
      "metadata": {
        "id": "wvQmLTNTHK_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_s.shape"
      ],
      "metadata": {
        "id": "47ytbwagZc5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step, (x_batch, y_batch) in train_dataset.enumerate():\n",
        "\n",
        "  print(x_batch.shape)\n",
        "  print(x_batch[:,0,:])"
      ],
      "metadata": {
        "id": "aso1fe0iaghE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fwpiX9DVakLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_s[0,:,:,0].shape"
      ],
      "metadata": {
        "id": "NDOoRHHcazsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# samples = gen_samples(model, y_test_s, ramp=ramp, nsamples=params['n_samples'])"
      ],
      "metadata": {
        "id": "2UY-_TYqc1KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_s.shape"
      ],
      "metadata": {
        "id": "AzPBfERvHi0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_s[0,:,0]"
      ],
      "metadata": {
        "id": "Da8VIwKqU_1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_mean, x_var = x_scaler.mean_, x_scaler.var_"
      ],
      "metadata": {
        "id": "ccjQSDp-JDgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_s[0,:,0] * np.sqrt(x_var) + x_mean"
      ],
      "metadata": {
        "id": "5-yAJVn_VMcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pcolormesh(y_test_s[0,:,:,0])"
      ],
      "metadata": {
        "id": "a6hya2HWV2s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = gen_samples(model, tf.expand_dims(y_test_s[0], axis=0), ramp=ramp, nsamples=200)"
      ],
      "metadata": {
        "id": "TDyMVC4HJHm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "MDvAVTlRULhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(samples[:,0])"
      ],
      "metadata": {
        "id": "8fisfx5fSTYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EBSA_mMUSU2K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}